{
  "ARTISSN (2025)": {
    "title": "ARTISSN (2025)",
    "images": [
      "v1764702148/Screenshot_2025-11-01_at_7.28.37_PM_ohgfau.png",
      "v1764201705/projects_grid_ylrxe7.png",
      "v1764201704/top_bids_ld3dzv.png",
      "v1764201704/script_mezgel.png"
    ],
    "about": {
      "links": {
        "artissn.com": "https://artissn.com",
        "Figma": "https://www.figma.com/design/k46GLXxt94xqHmYdo9ISpG/Artissn_designs?node-id=0-1&p=f&t=TderPG25v8eW2KzT-0"
      },
      "categories": [
        "UI",
        "Code"
      ],
      "description": "An AI-powered marketplace for product placement in film & TV. Filmmakers upload their screenplays, where we use AI to parse out potential product placement opportunities. Brands can then bid on these opportunities, which the filmmaker can either accept or decline. I worked on the UI/UX design through extensive FIgma mockups and conversations with our main engineer. I also worked on frontend development for several iterations of the MVP as well as the landing page."
    },
    "documentation": {
      "UI": {
        "links": {
          "Figma": "https://www.figma.com/design/k46GLXxt94xqHmYdo9ISpG/Artissn_designs?node-id=0-1&p=f&t=TderPG25v8eW2KzT-0"
        },
        "images": [
          "v1764201724/full_mockups_miemnx.png",
          "v1764202522/full_view_mockups_cjkkdy.png",
          "v1764201724/projects_grid_xi7lez.png",
          "v1764201705/projects_grid_ylrxe7.png",
          "v1764201728/top_bids_list_z5gtvz.png",
          "v1764201704/top_bids_ld3dzv.png",
          "v1764201725/scene_expanded_vieew_cbjwkb.png",
          "v1764201705/scenes_expanded_xbthmm.png",
          "v1764201726/script_view_clfffh.png",
          "v1764201704/script_mezgel.png"
        ]
      }
    }
  },

  "Rainer's Portfolio (2025)": {
    "title": "Rainer's Portfolio (2025)",
    "images": [
      "v1764620175/Frame_12-3_jrlitv.png",
      "v1764620232/Frame_13_sibut1.png",
      "v1764620255/Frame_8_xmmnpv.png"
    ],
    "about": {
      "links": {
        "GitHub": "https://github.com/rgo125/rainers_portfolio",
        "Figma": "https://www.figma.com/design/KnPwyNqz551wcMOntDrxrh/My-website?node-id=0-1&p=f&t=i7Unrs9Z5pocJzXc-0"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "A portfolio to showcase all my awesome projects (and that you're looking at right now!). I designed the website in Figma. I wanted to keep it simple and intuitive but also pretty. I built the website in React, with a robust system for displaying metadata for each project, using a large JSON file and smart rules for rendering components. I also integrated an image CDN to ensure the website is memory efficient across any device.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },

  "Wild Card (2025)": {
    "title": "Wild Card (2025)",
    "images": [
      "v1764635300/GardnerOlesen_Rainer_Image3_hv70bp.png",
      "v1764635305/GardnerOlesen_Rainer_Image2_k3jwlk.tiff",
      "v1764114106/GardnerOlesen_Rainer_Image1_sarrkc.tiff",
      "v1764635303/GardnerOlesen_Rainer_Image4_j4nqkh.png"
    ],
    "about": {
      "links": {
        "Full Video": "https://youtu.be/m6B87CEPH2I",
        "GitHub": "https://github.com/rgo125/final-project-lilnasyxers.git",
        "Procedural Backgrounds": "https://www.youtube.com/watch?v=1jRFnKs0GC8",
        "RISD": "https://favshow.risd.edu/Rainer-Gardner-Olesen-1"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "3D animated short film about a space station, floating through the galaxy. It is infiltrated by a mysterious figure. As he maneuvers around the complex maze that is the space station, it leaves us to wonder what heâ€™s after. This was my senior thesis at the Rhode Island School of Design. I used Maya for modelling and rigging characters and a mix of motion-capture data and manual keyframing for animating them. Fluid simulations were done in Houdini. Backgrounds were done procedurally through a C++ script, that generated points along a maze which I could sample custom assets along to fill out the space. Check out the GitHub for that project and the video on how I used this method for procedural backgrounds!",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },

  "Dancing With My Shadow (2025)": {
    "title": "Dancing With My Shadow (2025)",
    "images": [
      "v1764117215/daiella_image_flhl2y.png",
      "v1764636333/Screenshot_2025-12-01_at_4.43.26_PM_txcss2.png",
      "v1764636328/Screenshot_2025-12-01_at_4.44.10_PM_b1pjds.png"
    ],
    "about": {
      "links": {
        "VFX": "https://www.youtube.com/watch?v=3qLYDGIxJis&t=13s",
        "Full Video": "https://www.youtube.com/watch?v=BKXSJ0xOtbE"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "Music Video for Dancing With My Shadow by R&B artist Daiella. I did the VFX for the project in Houdini. I went over and expanded upon the art direction with the director in order to develop both artstic and technical workflows. We wanted to capture the essence of the singer's world \"disintegrating\" around her. I did this by implementing a node-based workflow in Houdini, combining perlin-noise and smoke simulation, to drive the displacement of quads in the mesh, achieving the desired effect.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },
  "ARTISSN Face Swap": {
    "title": "ARTISSN Face Swap (2025)",
    "images": [
      "v1764179219/face_swap_side_by_side_b17bxc.png"
    ],
    "about": {
      "links": {
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "Face swap solution for an HBO documentary. Worked off of a third-party codebase to train a model to output high-quality deepfakes to be used in production.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },
  "Pathtracer": {
    "title": "Pathtracer (2025)",
    "images": [
      "v1764116930/refraction_wmddzt.png",
      "v1764637938/glossy_ovvauj.png",
      "v1764637937/cornell_box_full_lighting_kwczti.png",
      "v1764637945/mirror_i3vlcy.png"
    ],
    "about": {
      "links": {
        "GitHub": "https://github.com/rgo125/path"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "This project implements a physics-based renderer that simulates realistic light transport across a scene, using Monte Carlo Integration and Hemisphere Sampling to model recursive light bounces and create physically-accurate reflection and refractions with Total Internal Reflections. Multiple BRDFs including Lambertian diffuse, glossy, and perfectly specular are implemented to accurately model how light interacts with various surface types.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },
  "Decision Tree": {
    "title": "Decision Tree (2024)",
    "images": [
      "v1764183882/decis_tree_nrsaih.svg"
    ],
    "about": {
      "links": {
        "GitHub": "https://github.com/rgo125/pr01-decision-tree.git"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "This project is a from-scratch implementation of a decision tree classifier in Java, featuring custom data structures, tree-building logic, and evaluation tools. It includes classes for representing datasets and rows, parsing CSV files, constructing decision trees using attribute-based splits, and evaluating predictions on test data. The system models tree components such as attribute nodes, value edges, and decision leaves, enabling the classifier to navigate through the tree and determine outcomes for new inputs. A dedicated testing framework validates dataset operations and tree generation, demonstrating a strong grasp of machine learning fundamentals, recursive algorithms, and object-oriented design.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },
  "Emergence": {
    "title": "Emergence (2024)",
    "images": [
      "v1764117562/Translation_thumbnail_gn5l5l.png",
      "v1764639730/Screenshot_2025-12-01_at_5.41.05_PM_oivvxj.png",
      "v1764639531/Screenshot_2025-12-01_at_5.37.41_PM_zi4iya.png",
      "v1764639723/Screenshot_2025-12-01_at_5.40.36_PM_oqsmrf.png"
    ],
    "about": {
      "links": {
        "Documentation": "https://vimeo.com/1002852906"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "A fully automated simulation of the cellular process of mRNA translation. I made this for the game \"Emergence\" during my time interning at Adroit Studios. The physics and functionality was coded in Unity and then brought into Blender to render a cinematic. I begin explaining the process at 1:45 in the documentation video linked.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },
  "Humanoid": {
    "title": "Deep Mimic (Training a Humanoid to Walk With Reinforcement Learning) (2025)",
    "images": [
      "v1764117696/Frame_44_mfa1ob.png",
      "v1764702942/Screenshot_2025-12-02_at_11.14.56_AM_gzqdyr.png",
      "v1764703085/Screenshot_2025-12-02_at_11.17.21_AM_wbu5gy.png"
    ],
    "about": {
      "links": {
        "GitHub": "https://github.com/effypelayotran/DeepMimic.git",
        "Original Paper": "https://xbpeng.github.io/projects/DeepMimic/index.html",
        "Presentation Slides": "https://docs.google.com/presentation/d/1fNaSF0vc3GV75YXFUuxBOuI8nCAfdlioqXwulEFPVus/edit?slide=id.p#slide=id.p"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "An implementation of the research paper: Deep Mimic. The project involved training a humanoid character to perform bipedal movements such as walking and running using Reinforcement Learning in a 3D simulated environment. What makes this project unique compared to other RL methods is the fact that motion-capture data is used to accelerate the training process. Reward is given to the agent for staying up right and moving in a straight line, but also for following the motion-capture data given to it. This gave us much higher quality results compared to pure RL methods.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },
  "ARAP": {
    "title": "As Rigid As Possible Surface Modelling (ARAP) (2025)",
    "images": [
      "v1764185079/arap_clntl4.png",
      "v1764704457/Screenshot_2025-12-02_at_11.38.22_AM_wtowgr.png",
      "v1764704456/Screenshot_2025-12-02_at_11.38.06_AM_wzj5k8.png",
      "v1764704465/Screenshot_2025-12-02_at_11.38.58_AM_szodpo.png"
    ],
    "about": {
      "links": {
        "GitHub": "https://github.com/rgo125/arap.git",
        "Original Paper": "https://igl.ethz.ch/projects/ARAP/arap_web.pdf"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "For this project, I implemented as rigid as possible surface modeling. This method is essentially an optimization problem that deforms a mesh \"as rigidly as possible\" given the constraints of a few vertices being set as anchors that can be manipulated freely by the user. Meshes are able to be deformed by clicking and dragging vertices, but they are able to maintain their form to some degree. This process consisted of solving a sparse linear matrix to find the best fit positions for every vertex in the mesh.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },
  "All I See": {
    "title": "All I See Now... (2023)",
    "images": [
      "v1764184591/Screenshot_2024-08-16_at_6.15.29_PM_uftfdm.png"
    ],
    "about": {
      "links": {
        "Full Video": "https://www.youtube.com/watch?v=K7marOb2CB0"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "Short film made during my sophomore year. Made using a unique blend of 3D digital elements as well as physical elements such as acrylic paint and hot glue.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },
  "AI Videos": {
    "title": "AI Video Experiments (2025)",
    "images": [
      "v1764117429/IMG_3283_vcded5.png",
      "v1764705563/Screenshot_2025-12-02_at_11.58.44_AM_laa31t.png"
    ],
    "about": {
      "links": {
        "IG Post": "https://www.instagram.com/p/DLlKzRQR5dA/"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "A few experiments with AI video generation. I collected a dataset of images from Pinterest that I liked and trained a LoRa for the image generation model: Flux. I used that to output some images and then brought them into Kling to add motion.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  }
}