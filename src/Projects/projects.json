{
  "ARTISSN (2025)": {
    "title": "ARTISSN (2025)",
    "images": [
      "v1764702148/Screenshot_2025-11-01_at_7.28.37_PM_ohgfau.png",
      "v1764201705/projects_grid_ylrxe7.png",
      "v1764201704/top_bids_ld3dzv.png",
      "v1764201704/script_mezgel.png"
    ],
    "about": {
      "links": {
        "artissn.com": "https://artissn.com",
        "Figma": "https://www.figma.com/design/k46GLXxt94xqHmYdo9ISpG/Artissn_designs?node-id=0-1&p=f&t=TderPG25v8eW2KzT-0"
      },
      "categories": [
        "UI",
        "Code"
      ],
      "description": "An AI-powered marketplace for product placement in film & TV. Filmmakers upload their screenplays where we use AI to parse out potential product placement opportunities. Brands can then bid on these opportunities, which the filmmaker can either accept or decline. I worked on the UI/UX design through extensive FIgma mockups and conversations with our main engineer. I also worked on frontend development for several iterations of demos for the MVP as well as the landing page."
    },
    "documentation": {
      "UI": {
        "links": {
          "Figma": "https://www.figma.com/design/k46GLXxt94xqHmYdo9ISpG/Artissn_designs?node-id=0-1&p=f&t=TderPG25v8eW2KzT-0"
        },
        "images": [
          "v1764201724/full_mockups_miemnx.png",
          "v1764202522/full_view_mockups_cjkkdy.png",
          "v1764201724/projects_grid_xi7lez.png",
          "v1764201705/projects_grid_ylrxe7.png",
          "v1764201728/top_bids_list_z5gtvz.png",
          "v1764201704/top_bids_ld3dzv.png",
          "v1764201725/scene_expanded_vieew_cbjwkb.png",
          "v1764201705/scenes_expanded_xbthmm.png",
          "v1764201726/script_view_clfffh.png",
          "v1764201704/script_mezgel.png"
        ]
      }
    }
  },

  "Rainer's Portfolio (2025)": {
    "title": "Rainer's Portfolio (2025)",
    "images": [
      "v1764620175/Frame_12-3_jrlitv.png",
      "v1764620232/Frame_13_sibut1.png",
      "v1764620255/Frame_8_xmmnpv.png"
    ],
    "about": {
      "links": {
        "GitHub": "https://github.com/rgo125/rainers_portfolio",
        "Figma": "https://www.figma.com/design/KnPwyNqz551wcMOntDrxrh/My-website?node-id=0-1&p=f&t=i7Unrs9Z5pocJzXc-0"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "A portfolio to showcase all my awesome projects (and that you're looking at right now!). I designed the website in Figma. I wanted to keep it simple and intuitive while still being pretty. I built the website in React, with a robust system for displaying metadata for each project using a JSON file and smart rules for rendering components. I also integrated an image CDN to ensure the website is memory efficient across any device.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },

  "Wild Card (2025)": {
    "title": "Wild Card (2025)",
    "images": [
      "v1764635300/GardnerOlesen_Rainer_Image3_hv70bp.png",
      "v1764635305/GardnerOlesen_Rainer_Image2_k3jwlk.tiff",
      "v1764114106/GardnerOlesen_Rainer_Image1_sarrkc.tiff",
      "v1764635303/GardnerOlesen_Rainer_Image4_j4nqkh.png"
    ],
    "about": {
      "links": {
        "Full Video": "https://youtu.be/m6B87CEPH2I",
        "GitHub": "https://github.com/rgo125/final-project-lilnasyxers.git",
        "Procedural Backgrounds": "https://www.youtube.com/watch?v=1jRFnKs0GC8",
        "RISD": "https://favshow.risd.edu/Rainer-Gardner-Olesen-1"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "3D animated short film about a space station, floating through the galaxy. It is infiltrated by a mysterious figure. As he maneuvers around the complex maze that is the space station, it leaves us to wonder what heâ€™s after. This was my senior thesis at the Rhode Island School of Design. I used Maya for modelling and rigging characters and a mix of motion-capture data and manual keyframing for animating them. Fluid simulations were done in Houdini. Backgrounds were done procedurally a C++ script, that generated points along a maze which I could generate customa assets along to fill out the space. Check out the GitHub for that project and the full video on how I applied it to this project!",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },

  "Dancing With My Shadow (2025)": {
    "title": "Dancing With My Shadow (2025)",
    "images": [
      "v1764117215/daiella_image_flhl2y.png",
      "v1764636333/Screenshot_2025-12-01_at_4.43.26_PM_txcss2.png",
      "v1764636328/Screenshot_2025-12-01_at_4.44.10_PM_b1pjds.png"
    ],
    "about": {
      "links": {
        "VFX": "https://www.youtube.com/watch?v=3qLYDGIxJis&t=13s",
        "Full Video": "https://www.youtube.com/watch?v=BKXSJ0xOtbE"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "Music Video for Dancing With My Shadow by R&B artist Daiella. I did the VFX for the project in Houdini. I went over and expanded upon the art direction with the director in order to develop both artstic and technical workflows. We wanted to capture the essence of the singer's world \"disintegrating\" around her. I implemented this into a node-based workflow in Houdini that was a combination of perlin-noise and a smoke simulation used to drive the displacement of quads in the mesh.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },
  "ARTISSN Face Swap": {
    "title": "ARTISSN Face Swap (2025)",
    "images": [
      "v1764179219/face_swap_side_by_side_b17bxc.png"
    ],
    "about": {
      "links": {
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "Face swap solution for an HBO documentary. Worked off of a third-party codebase to train a model to output high-quality deepfakes to be used in production.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },
  "Pathtracer": {
    "title": "Pathtracer (2025)",
    "images": [
      "v1764116930/refraction_wmddzt.png",
      "v1764637938/glossy_ovvauj.png",
      "v1764637937/cornell_box_full_lighting_kwczti.png",
      "v1764637945/mirror_i3vlcy.png"
    ],
    "about": {
      "links": {
        "GitHub": "https://github.com/rgo125/path"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "This project implements a physics-based renderer that simulates realistic light transport across a scene, using Monte Carlo Integration and Hemisphere Sampling to model recursive light bounces and create physically-accurate reflection and refractions with Total Internal Reflections. Multiple BRDFs including Lambertian diffuse, glossy, and perfectly specular are implemented to accurately model how light interacts with various surface types.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },
  "Decision Tree": {
    "title": "Decision Tree (2024)",
    "images": [
      "v1764183882/decis_tree_nrsaih.svg"
    ],
    "about": {
      "links": {
        "GitHub": "https://github.com/rgo125/pr01-decision-tree.git"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "This project is a from-scratch implementation of a decision tree classifier in Java, featuring custom data structures, tree-building logic, and evaluation tools. It includes classes for representing datasets and rows, parsing CSV files, constructing decision trees using attribute-based splits, and evaluating predictions on test data. The system models tree components such as attribute nodes, value edges, and decision leaves, enabling the classifier to navigate through the tree and determine outcomes for new inputs. A dedicated testing framework validates dataset operations and tree generation, demonstrating a strong grasp of machine learning fundamentals, recursive algorithms, and object-oriented design.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },
  "Emergence": {
    "title": "Emergence (2024)",
    "images": [
      "v1764117562/Translation_thumbnail_gn5l5l.png",
      "v1764639730/Screenshot_2025-12-01_at_5.41.05_PM_oivvxj.png",
      "v1764639531/Screenshot_2025-12-01_at_5.37.41_PM_zi4iya.png",
      "v1764639723/Screenshot_2025-12-01_at_5.40.36_PM_oqsmrf.png"
    ],
    "about": {
      "links": {
        "Documentation": "https://vimeo.com/1002852906"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "A fully automated simulation of the cellular process of mRNA translation. I made this for the game \"Emergence\" during my time interning at Adroit Studios. The physics and functionality was coded in Unity and then brought into Blender to render a cinematic. I begin explaining the process at 1:45 in the video linked.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  },
  "Humanoid": {
    "title": "Deep Mimic (Training a Humanoid to Walk With Reinforcement Learning) (2025)",
    "images": [
      "v1764117696/Frame_44_mfa1ob.png",
      "v1764702942/Screenshot_2025-12-02_at_11.14.56_AM_gzqdyr.png",
      "v1764703085/Screenshot_2025-12-02_at_11.17.21_AM_wbu5gy.png"
    ],
    "about": {
      "links": {
        "GitHub": "https://github.com/effypelayotran/DeepMimic.git",
        "Original Paper": "https://xbpeng.github.io/projects/DeepMimic/index.html",
        "Presentation Slides": "https://docs.google.com/presentation/d/1fNaSF0vc3GV75YXFUuxBOuI8nCAfdlioqXwulEFPVus/edit?slide=id.p#slide=id.p"
      },
      "categories": [
        "Animation",
        "Code"
      ],
      "description": "An implementation of the research paper: Deep Mimic. The project involved training a humanoid character to perform bipedal movements such as walking and running using Reinforcement Learning in a 3D simulated environment. What makes this project unique compared to other RL methods is the fact that motion-capture data is to accelerate the training process. Reward is given to the agent for staying up right and moving in a straight line, but also for following the motion-capture data given to it. This gave us much higher quality resutls compared to the pure RL methods.",
      "full_movie": "Url for movie"
    },
    "documentation": {
      "Animation": {
        "links": [
          "YouTube"
        ],
        "images": [
          "Image 1 url"
        ]
      },
      "Code": {
        "links": [
          "GitHub"
        ],
        "videos": [
          "Video url"
        ],
        "images": [
          "Image 1 url"
        ]
      }
    }
  }
}